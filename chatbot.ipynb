{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POOJA-BFRS01535/chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUP8b9BC3Y42"
      },
      "source": [
        "\n",
        "# Ecommerce Chatbot\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Design a chatbot which can be used by any D2C ecommerce company to answer first level most common queries of their customers. If chatbot is unable to support it will then only pass the customer to manual customer support. This will help in reducing the no of support agents required to answer user questions plus customers will get a quicker response without having to wait for replies for basic questions.\n",
        "\n",
        "**Use** **cases to solve**\n",
        "\n",
        "\n",
        "1.   Order related questions\n",
        "2.   Product information\n",
        "3. Return and Refund queries\n",
        "4. Shipment status\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPO-QTcq3PZz"
      },
      "source": [
        "# Version 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTEVJn0R4WJl"
      },
      "source": [
        "### Chatbot for post order journey ecommerce sellers\n",
        "* `initialise_conversation()`\n",
        "Identify intent of each user message. If not clear ask further questions. If still not clear redirect to manual agent. `identify_intent()`\n",
        "* `check_intent_supported()`\n",
        "Once intent is identified if intent is from list of supported intent then take the flow as per that intent else redirect to manual agent.\n",
        "\n",
        "* For get order details intent\n",
        "\n",
        "  * get order id from user - `get_order_id`\n",
        "  * once obtained - pull out order info from db/shopify API and make it json. - `extract_order_info`\n",
        "  * Based on what user asked prepare response - `prepare_order_response`\n",
        "* For get product details\n",
        "  * get ecommerce site url from settings for example phool.co\n",
        "  * first check what the user has asked. Form a seach query for it. `create_search_query`\n",
        "  * Then go to website of the ecommerce company and search for the product in it. `perform_search`\n",
        "  * then formulate the results and respond back - `respond_to_user_query`\n",
        "* For return and refund info\n",
        "  * get details of return and refund policy of company from urls of the pages in their websites in settings - `prepare_refund_return_policy`\n",
        "  * answer user query based on the return and refund policy - `return_return_refund_policy_info`\n",
        "* Get_shipment_info\n",
        "  * get shipment awb from user - `get_shipment_awb`\n",
        "  * once obtained - pull out order info from shiprocket API and pull relevant info from it. - `get_shipment_info`\n",
        "  * Based on what user asked prepare response - `prepare_shipment_response`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4aPTB9nVMue"
      },
      "source": [
        "###  Problems Faced\n",
        "  As I started working on this approach I got confused with 2 questions.\n",
        "  * How do I manage if user changes intent mid conversation? How will the system design look for it?\n",
        "  * How do I continue the conversation after I have switched to the another flow for like get order details etc. As I want chatbot to pick up conservation from where it left so that it looks like human like interaction.\n",
        "\n",
        "  Both these questions made it difficult to design the system. After attending the part 2 of shop assist I decided to for now make assumptions that the chatbot will not encounter above scenarios. User will not change intent and only one intent will be handled at a time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Version\n",
        "\n",
        "* Merged the get order status and get shipment status steps as they looked similar. Made both to work with Shiprocket API\n",
        "* For both product info and Refund and return policy step had to depend on files to read data rather than getting it from web as could not figure out making web requests\n",
        "* `display` function showed some weird behavior. Whenever used it would intermittenly cause the input in next line to now show. Program would keep running waiting for input but not input would be present. Replacing `display` with `print` fixed this problem.\n"
      ],
      "metadata": {
        "id": "w_My8X80ZahM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GmousiuEzAU",
        "outputId": "0bd45ab5-4eb5-4d5f-aa59-720e9d460910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "OPENAI_API_Key.txt  products.csv  returns_refund.txt\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI library\n",
        "!pip install -U -q openai tenacity\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/upgrad/GenAI_Course_Master/Chatbot_Project/')\n",
        "!ls\n",
        "\n",
        "# Import the libraries\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "# Set the display width to control the output width\n",
        "pd.set_option('display.width', 100)\n",
        "# Read the dataset and read the Laptop Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "vEd32HLQHE-h"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import os, json, ast\n",
        "import requests\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "# read the OpenAI API key\n",
        "openai.api_key = open(\"OPENAI_API_Key.txt\", \"r\").read().strip()\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Lq8YJLZFHhHS"
      },
      "outputs": [],
      "source": [
        "# INTENTS = {\n",
        "#     \"order_status\": [\"order status\", \"track my order\", \"where is my order\", \"order information\", \"details of order\", \"order confirmation\", \"order history\"],\n",
        "#     \"product_info\": [\"product features\", \"product details\", \"product info\"],\n",
        "#     \"return_policy\": [\"return policy\", \"how to return\", \"refund policy\"],\n",
        "#     \"shipping_info\": [\"shipping details\", \"delivery time\", \"shipping info\"],\n",
        "# }\n",
        "\n",
        "INTENTS = {\n",
        "    \"order_status\": [\n",
        "        \"order status\", \"order information\", \"order details\", \"order update\", \"order number\",\n",
        "        \"details of order\", \"order confirmation\", \"order history\", \"check my order\",\n",
        "        \"shipping details\", \"delivery time\", \"shipping info\", \"shipment status\",\n",
        "        \"where is my shipment\", \"track my shipment\", \"delivery status\", \"shipping status\",\n",
        "        \"when will my order arrive\", \"delivery tracking\", \"shipping update\",\n",
        "        \"estimated delivery\", \"shipment tracking\",  \"order tracking\", \"order not received\",\n",
        "        \"track my order\", \"where is my order\"\n",
        "    ],\n",
        "    \"product_info\": [\n",
        "        \"product features\", \"product details\", \"product info\", \"product specifications\",\n",
        "        \"product availability\", \"product compatibility\", \"product description\",\n",
        "        \"product price\", \"product reviews\", \"product warranty\", \"compare products\",\n",
        "        \"product colors\", \"product sizes\"\n",
        "    ],\n",
        "    \"return_policy\": [\n",
        "        \"return policy\", \"how to return\", \"refund policy\", \"return process\",\n",
        "        \"return item\", \"return instructions\", \"exchange policy\", \"refund process\",\n",
        "        \"how to exchange\", \"return guidelines\", \"refund request\", \"return eligibility\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "ECOM_WEBSITE = \"https://phool.co/\"\n",
        "\n",
        "REFUND_URL = \"https://phool.co/pages/terms-of-use\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLGCa8e8I0dP",
        "outputId": "b98b83fa-c70c-456c-9ff8-0ce2a0cf4bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['order_status', 'product_info', 'return_policy'])\n"
          ]
        }
      ],
      "source": [
        "print(INTENTS.keys())\n",
        "\n",
        "products_df = pd.read_csv('products.csv')\n",
        "\n",
        "products_df.head()\n",
        "\n",
        "return_refund_policy = open(\"returns_refund.txt\", \"r\").read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "yTPGFfB-HT8m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    system_message = \"\"\"\n",
        "    You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to identify the intent of incoming customer queries.\n",
        "    You will be handling 3 types of user queries. Check user order, check status of shipment, get product info, answer questions about return and refund policy.\n",
        "    In case user asks questions which you do not know how to handle redirect user to manual customer support.\n",
        "\n",
        "    You need to ask relevant questions and understand the user intent first and reply back with what is user intent out of below intents.\n",
        "    If you are unable to identify intent continue the conversation till to find the intent.\n",
        "    In below dictionary, keys are intents and the list of values for each key represent some sample input which user can give for that intent.\n",
        "    Based on these sample inputs identify the intent of user.\n",
        "    {delimiter}\n",
        "    {INTENTS}\n",
        "    {delimiter}\n",
        "\n",
        "    Your output should be a single word intent out of {INTENTS.keys()}. If you are unable to identify indent then continue conversation with user.\n",
        "\n",
        "    {delimiter}\n",
        "\n",
        "\n",
        "    ### Examples:\n",
        "\n",
        "Example 1:\n",
        "\n",
        "Customer Query: \"Can you tell me where my package is right now?\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "Example 2:\n",
        "\n",
        "Customer Query: \"I need information on how to return a product I purchased last week.\"\n",
        "Response: \"return_policy\"\n",
        "\n",
        "Example 3:\n",
        "\n",
        "Customer Query: \"What are the features of the new smartphone you have on sale?\"\n",
        "Response: \"product_info\"\n",
        "\n",
        "Example 4:\n",
        "\n",
        "Customer Query: \"I haven't received an order confirmation email. Can you check my order?\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "\n",
        "Example 5:\n",
        "\n",
        "Customer Query: \"Hi\"\n",
        "Response: \"Hi! How can I help you?\"\n",
        "Customer Follow-Up: \"It's about the delivery of my order 233.\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "\n",
        "Example 6:\n",
        "\n",
        "Customer Query: \"I need assistance.\"\n",
        "Response: \"Hello! I'm here to assist you. Can you please tell me if want to know more about our products, or some existing order. I can also help you with our return and refund policy.\"\n",
        "Customer Follow-Up: \"nothing\"\n",
        "Response: \"Sorry I could not understand your question. Can you please tell me if want to know more about our products, or some existing order. I can also help you with our return and refund policy.\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    return conversation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "I9zdS4DrJc_w"
      },
      "outputs": [],
      "source": [
        "# Define a Chat Completions API call\n",
        "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions(input, json_format = False):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
        "\n",
        "    # If the output is required to be in JSON format\n",
        "    if json_format == True:\n",
        "        # Append the input prompt to include JSON response as specified by OpenAI\n",
        "        input[0]['content'] += system_message_json_output\n",
        "\n",
        "        # JSON return type specified\n",
        "        chat_completion_json = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            response_format = { \"type\": \"json_object\"},\n",
        "            seed = 9877)\n",
        "\n",
        "        output = json.loads(chat_completion_json.choices[0].message.content)\n",
        "\n",
        "    # No JSON return type specified\n",
        "    else:\n",
        "        chat_completion = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            seed = 9866)\n",
        "\n",
        "        output = chat_completion.choices[0].message.content\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "u8MJV-oBJqAJ"
      },
      "outputs": [],
      "source": [
        "# system_msg = initialize_conversation()\n",
        "# debug_conversation = system_msg\n",
        "# print(system_msg[0][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "fTdIPaIDJ0hx"
      },
      "outputs": [],
      "source": [
        "# user_input1 = \"Hi\"\n",
        "# debug_conversation.append({'role':'user','content':user_input1})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "tEV6SA5qLP4o"
      },
      "outputs": [],
      "source": [
        "# debug_conversation.append(({\"role\": \"assistant\", \"content\": debug_response_assistant}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "EWQcRA4MLWS-"
      },
      "outputs": [],
      "source": [
        "# debug_conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pb-ImttRNyE-"
      },
      "outputs": [],
      "source": [
        "# user_input2 = \"I want to know more about refund policy\"\n",
        "# last_user_msg = user_input2\n",
        "# debug_conversation.append({'role':'user','content':user_input2})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n",
        "# print(debug_response_assistant)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "x_Ba3qIFQPIl"
      },
      "outputs": [],
      "source": [
        "def check_intent_identified(assistant_response):\n",
        "  if assistant_response in INTENTS.keys():\n",
        "    return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "RHjTZPC8XQmj"
      },
      "outputs": [],
      "source": [
        "# def get_order_id(last_user_input):\n",
        "#   delimiter = \"####\"\n",
        "#   confirm_order_id_msgs = [\n",
        "#       {'role':'system','content':f\"\"\"\n",
        "#         You are a customer support executive. Need your help to check if user has passed order id in the input in the message.\n",
        "#         Reply back with a json having 2 keys.\n",
        "#         'order_id_present' which will either be 'true' or 'false' based on whether order is present,\n",
        "#         and order_id which will contain order_id when present and null when not.\n",
        "#         {delimiter}\"\"\"},\n",
        "#       {'role': 'user', 'content': f\"Here is the message {last_user_input}\"}\n",
        "#       ]\n",
        "#   response = openai.chat.completions.create(\n",
        "#       model=\"gpt-3.5-turbo\",\n",
        "#       messages = confirm_order_id_msgs,\n",
        "#       response_format={ \"type\": \"json_object\" },\n",
        "#       seed = 1234\n",
        "#       )\n",
        "#   json_output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "#   if json_output.get('order_id_present'):\n",
        "#     return json_output.get('order_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "TUn0lydWXM0R"
      },
      "outputs": [],
      "source": [
        "def moderation_check(user_input):\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    response = openai.moderations.create(input=user_input)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    moderation_output = response.results[0].flagged\n",
        "    # Check if the input was flagged by the moderation system.\n",
        "    if response.results[0].flagged == True:\n",
        "        # If flagged, return \"Flagged\"\n",
        "        return \"Flagged\"\n",
        "    else:\n",
        "        # If not flagged, return \"Not Flagged\"\n",
        "        return \"Not Flagged\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "dMcQ6y3Dv0iN"
      },
      "outputs": [],
      "source": [
        "def get_order_details(order_id):\n",
        "  # print(\"inside get order details\")\n",
        "  # return {\n",
        "  #     'order_id': 122,\n",
        "  #     'total_amount': 299.99,\n",
        "  #     'delivery_status': 'Shipped',\n",
        "  #     'current_location': 'Warehouse B',\n",
        "  #     'expected_delivery_date': '2023-01-18',\n",
        "  #     'customer_name': 'Alice Brown',\n",
        "  #     'product_id': 4,\n",
        "  #     'product_name': 'Tablet'\n",
        "  #     }\n",
        "\n",
        "  # https://apiv2.shiprocket.in/v1/tracking/19041580387436\n",
        "  url = f\"https://apiv2.shiprocket.in/v1/tracking/{order_id}\"  # Replace with your actual endpoint\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "      return response.json()\n",
        "  else:\n",
        "      return f\"Error: Unable to fetch order details. Status code: {response.status_code}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to search product details\n",
        "def search_product(query):\n",
        "  results = products_df[products_df.apply(lambda row: query.lower() in row['Product Name'].lower() or query.lower() in row['Description'].lower(), axis=1)]\n",
        "  product_info = \"\\n\".join([f\"Title: {row['Product Name']}, Price: {row['Price (INR)']}, URL: {row['URL']}, Description: {row['Description']}\" for index, row in results.iterrows()])\n",
        "  return product_info\n",
        "\n"
      ],
      "metadata": {
        "id": "HF32WzHbbQzB"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "KQKizJNSl9WH"
      },
      "outputs": [],
      "source": [
        "\n",
        "available_functions = {\n",
        "    \"get_order_details\": get_order_details,\n",
        "    \"search_product\": search_product\n",
        "}\n",
        "\n",
        "def execute_function_call(function_name, arguments):\n",
        "    function = available_functions.get(function_name, None)\n",
        "    if function:\n",
        "        arguments = json.loads(arguments)\n",
        "        results = function(**arguments)\n",
        "    else:\n",
        "        results = f\"Error: function {function_name} does not exist\"\n",
        "    return results\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions_with_functions(input, functions):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model = MODEL,\n",
        "        messages = input,\n",
        "        functions = functions,\n",
        "        function_call = \"auto\",  # Automatically call the function when needed\n",
        "        seed = 2345)\n",
        "\n",
        "    output = chat_completion.choices[0].message.content\n",
        "\n",
        "    print(\"chat_completion.choices[0].message: \", chat_completion.choices[0].message)\n",
        "\n",
        "    #if function called then call function, get details and then call chat completion once more with function o/p\n",
        "    # print(\"chat_completion.choices[0].message.function_call\", chat_completion.choices[0].message.function_call)\n",
        "    if chat_completion.choices[0].message.function_call:\n",
        "      # print(\"function called\")\n",
        "\n",
        "      function_name = chat_completion.choices[0].message.function_call.name\n",
        "      arguments = chat_completion.choices[0].message.function_call.arguments\n",
        "      # print(\"function_name. \", function_name)\n",
        "      # print(\". rguments :\", arguments)\n",
        "      function_response = execute_function_call(function_name, arguments)\n",
        "      # print(\"function_response: \", function_response)\n",
        "\n",
        "      input.append(chat_completion.choices[0].message)\n",
        "      input.append({\n",
        "          \"role\": \"function\",\n",
        "          \"name\": function_name,\n",
        "          \"content\": str(function_response),\n",
        "      })\n",
        "      output = get_chat_completions_with_functions(input, functions)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "u8X14v85lJs2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_order_info(user_input):\n",
        "  \"\"\"\n",
        "  get order id from user - get_order_id\n",
        "  once obtained - pull out order info from db/shopify API and make it json. - extract_order_info\n",
        "  Based on what user asked prepare response - prepare_order_response\n",
        "  \"\"\"\n",
        "  # print(\"inside get order info\")\n",
        "  tools = [\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Gets the details of an order by order ID\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The ID of the order to retrieve\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  # first get order details\n",
        "  conversation = get_order_initialisation(user_input)\n",
        "  response_assistant = get_chat_completions_with_functions(conversation, functions=tools)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    print(\"inside order info while loop\")\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions_with_functions(conversation, functions=tools)  # Get assistant response\n",
        "    print(response_assistant)  # Display assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "  return \"exit\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "n-v73_8ZfNFL"
      },
      "outputs": [],
      "source": [
        "def get_order_initialisation(user_input):\n",
        "\n",
        "  delimiter = \"####\"\n",
        "\n",
        "  system_message = f\"\"\"\n",
        "  You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to handle order related queries of a customer.\n",
        "  Customer has been forwarded to you from a chat with an existing agent as user showed intent to know about their order details.\n",
        "  You are expert in answering users order related queries.\n",
        "   Do not say any greetings to user in begining as customer is coming from an existing chat and our aim will be provide a consistent experience.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from prev chat was {user_input}\n",
        "\n",
        "  {delimiter}\n",
        "\n",
        "  The conversation flow involves three main thoughts. Follow these chain of thoughts and converse with the customer as customer support agent.\n",
        "    - Thought 1: Obtaining the order id from user. First check if order id already exists in the users last message. If not then ask for it from user.\n",
        "    - Thought 2: Once order id is obtained from user, then fetching details of the order from obtained order id using get_order_details.\n",
        "    - Thought 3: Once we have order details from previous step, then find answer to user queries from the order details and reply back to customer with answer to their query.\n",
        "\n",
        "  {delimiter}\n",
        "  In case user asks questions which you do not know how to handle redirect user to manual customer support on support@support.com or call on 9383838338. Post that reply back with word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "\n",
        "  If you are unable to find the details of order id shared by customer then tell them \"Sorry, I am unable to find any order with order id <order id>. Please check and share order id again.\"\n",
        "\n",
        "  {delimiter}\n",
        "  Order information should always be accurate based on output received from get_order_details.\n",
        "\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping user reply back with a single word \"exit\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_product_info_initialisation(last_message):\n",
        "  delimiter = \"####\"\n",
        "  system_message = f\"\"\"\n",
        "\n",
        "  You are an experienced customer support agent for an ecommerce direct-to-customer brand, and your goal is to handle product-related queries of a customer.\n",
        "  The customer has been forwarded to you from a chat with an existing agent as the user showed intent to know about products of the ecommerce company.\n",
        "  You are an expert in answering users' product-related queries.\n",
        "  Do not say any greetings to the user in the beginning as the customer is coming from an existing chat and our aim is to provide a consistent experience. Everytime you provide some answer ask your further question if needed else reply back with exit keyword.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from previous chat was \"{last_message}\"\n",
        "  {delimiter}\n",
        "\n",
        "  The conversation flow involves three main thoughts. Follow these chain of thoughts and converse with the customer as a customer support agent:\n",
        "    - Step 1: First evaluate what the user has asked in the last message and form a search query for it. If it is not clear to you what details the user is looking for, then ask further questions to clarify it and then form the search query.\n",
        "    - Step 2: Fetch details of the product using search_product function.\n",
        "    - Step 3: Based on output of search_product if any products found, answer user query else inform user that the product is not available.\n",
        "\n",
        "\n",
        "  {delimiter}\n",
        "  Product information should always be accurate and based on the output received from search product.\n",
        "\n",
        "  In case the user asks questions which you do not know how to handle, redirect the user to manual customer support at support@support.com or call 9383838338. Post that, reply back with the word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping the user, reply back with a single word \"exit\".\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "d_eiQtamwfQt"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_return_info_initialisation(last_message, refund_policy):\n",
        "  delimiter = \"####\"\n",
        "  system_message = f\"\"\"\n",
        "\n",
        "  You are an experienced customer support agent for an ecommerce direct-to-customer brand, and your goal is to handle return and refund related queries of a customer.\n",
        "  The customer has been forwarded to you from a chat with an existing agent as the user had question about return and refunds.\n",
        "  You are an expert in answering users' refund and return related queries based on return and refund policy provided below.\n",
        "  Do not say any greetings to the user in the beginning as the customer is coming from an existing chat and our aim is to provide a consistent experience.\n",
        "  Everytime you provide some answer ask your further question if needed else reply back with exit keyword.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from previous chat was \"{last_message}\"\n",
        "  {delimiter}\n",
        "\n",
        "  Refund and return policy\n",
        "  {refund_policy}\n",
        "\n",
        "  {delimiter}\n",
        "  Your answers should always be accurate based on the Refund and return policy provided above.\n",
        "  In case the user asks questions which you do not know how to handle, redirect the user to manual customer support at support@support.com or call 9383838338. Post that, reply back with the word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping the user, reply back with a single word \"exit\".\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "wlN6r14wwgiL"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "OcU33i9RlLFL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_product_info(user_input):\n",
        "  \"\"\"\n",
        "  get ecommerce site url from settings for example phool.co\n",
        "  first check what user has asked. Form a seach query for it. create_search_query\n",
        "  Then go to website of the ecommerce company and search for the product in it. perform_search\n",
        "  then formulate the results and respond back - respond_to_user_query\n",
        "  \"\"\"\n",
        "  tools = [\n",
        "    {\n",
        "        \"name\": \"search_product\",\n",
        "        \"description\": \"Search for product in product db\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"query to be searched for in product databased\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"query\"]\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  conversation = get_product_info_initialisation(user_input)\n",
        "  response_assistant = get_chat_completions(conversation)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    # print(\"inside product info while loop\")\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions_with_functions(conversation, functions=tools)  # Get assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "    print(response_assistant)  # Display assistant response\n",
        "  return \"exit\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_return_policy_info(user_input):\n",
        "  \"\"\"\n",
        "  get details of return and refund policy of company from a text document\n",
        "  answer user query based on the return and refund policy - return_return_refund_policy_info\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = get_return_info_initialisation(user_input, return_refund_policy)\n",
        "  response_assistant = get_chat_completions(conversation)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions(conversation)  # Get assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "    print(response_assistant)  # Display assistant response\n",
        "  return \"exit\"\n"
      ],
      "metadata": {
        "id": "QdILrxwUynSQ"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "tbVSaFVIyalV"
      },
      "outputs": [],
      "source": [
        "\n",
        "INTENT_to_action_map = {\n",
        "    \"order_status\": get_order_info,\n",
        "    \"product_info\": get_product_info,\n",
        "    \"return_policy\": get_return_policy_info,\n",
        "}\n",
        "\n",
        "\n",
        "def chatbot():\n",
        "  initial_input = input(\"Enter your query to start conversation with our support>>>>>\\n \")\n",
        "  user_input = \"\"\n",
        "  conversation = initialize_conversation()\n",
        "  is_intent_identified = False\n",
        "  while(user_input != \"exit\" and response_assistant != \"exit\"):\n",
        "    user_input = initial_input or input(\"\")\n",
        "    moderation = moderation_check(user_input)\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      initial_input = \"\"\n",
        "      break\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "    response_assistant = get_chat_completions(conversation)\n",
        "    is_intent_identified = check_intent_identified(response_assistant)\n",
        "    if is_intent_identified:\n",
        "      action = INTENT_to_action_map.get(response_assistant)\n",
        "      response_assistant = action(user_input)\n",
        "    else:\n",
        "      conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "      print(str(response_assistant))\n",
        "    initial_input = \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "hmxawazSfnd9",
        "outputId": "ef094a5d-0af1-4ec6-ae23-82055a8574e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query to start conversation with our support>>>>>\n",
            " i want to return my order\n",
            "How can I assist you with your return request?\n",
            "i want to know more about return policy\n",
            "If you want to return your order, we can only accept return requests if the products delivered to you are incorrect, damaged, or defective. You must notify us within 48 hours after receiving the product. We would also need clear pictures either sent to us by email or WhatsApp to raise a ticket regarding this. \n",
            "Do you have any specific questions about the return process?\n",
            "when can i expect refund post return\n",
            "Once we receive your returned product and confirm that it meets the criteria for return (incorrect, damaged, or defective), we will process your refund. The time it takes for the refund to reflect in your account may vary depending on your payment method and financial institution. If you have any more questions or need assistance with your return, feel free to ask.\n",
            "no further question\n",
            "Great! If you need any more help in the future or have any other questions, feel free to reach out. Have a nice day! \n",
            "exit\n",
            "exit\n",
            "exit\n",
            "exit\n",
            "Hello! I'm here to assist you. Can you please tell me if you want to know more about our products, the status of an existing order, or information about our return and refund policy?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-ac2b5f38ccd9>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# can test with order id 19041580387436\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-a3525ba9a1a1>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mis_intent_identified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"exit\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresponse_assistant\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_input\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mmoderation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoderation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmoderation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Flagged'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "# can test with order id 19041580387436\n",
        "\n",
        "chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEEUaojBfbke"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for refund or return policy questions:\n",
        "#   1. Go to website {REFUND_URL} and get details of refund and return policy\n",
        "#   2. check if answer to user query is present in refund and return policy\n",
        "#   3. If present reply back to user with relevant details\n",
        "#   4. if relevant results not found redirect user to manual support\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJV7rW2PsSwCpZxmSGBBRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}