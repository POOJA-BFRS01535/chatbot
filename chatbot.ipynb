{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyMoDVNC4bMnLcWFXUW5yw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POOJA-BFRS01535/chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Ecommerce Chatbot\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Design a chatbot which can be used by any D2C ecommerce company to answer first level most common queries of their customers. If chatbot is unable to support it will then only pass the customer to manual customer support. This will help in reducing the no of support agents required to answer user questions plus customers will get a quicker response without having to wait for replies for basic questions.\n",
        "\n",
        "**Use** **cases to solve**\n",
        "\n",
        "\n",
        "1.   Order related questions\n",
        "2.   Product information\n",
        "3. Return and Refund queries\n",
        "4. Shipment status\n"
      ],
      "metadata": {
        "id": "tUP8b9BC3Y42"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Version 1"
      ],
      "metadata": {
        "id": "FPO-QTcq3PZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chatbot for post order journey ecommerce sellers\n",
        "* `initialise_conversation()`\n",
        "Identify intent of each user message. If not clear ask further questions. If still not clear redirect to manual agent. `identify_intent()`\n",
        "* `check_intent_supported()`\n",
        "Once intent is identified if intent is from list of supported intent then take the flow as per that intent else redirect to manual agent.\n",
        "\n",
        "* For get order details intent\n",
        "\n",
        "  * get order id from user - `get_order_id`\n",
        "  * once obtained - pull out order info from db/shopify API and make it json. - `extract_order_info`\n",
        "  * Based on what user asked prepare response - `prepare_order_response`\n",
        "* For get product details\n",
        "  * get ecommerce site url from settings for example phool.co\n",
        "  * first check what the user has asked. Form a seach query for it. `create_search_query`\n",
        "  * Then go to website of the ecommerce company and search for the product in it. `perform_search`\n",
        "  * then formulate the results and respond back - `respond_to_user_query`\n",
        "* For return and refund info\n",
        "  * get details of return and refund policy of company from urls of the pages in their websites in settings - `prepare_refund_return_policy`\n",
        "  * answer user query based on the return and refund policy - `return_return_refund_policy_info`\n",
        "* Get_shipment_info\n",
        "  * get shipment awb from user - `get_shipment_awb`\n",
        "  * once obtained - pull out order info from shiprocket API and pull relevant info from it. - `get_shipment_info`\n",
        "  * Based on what user asked prepare response - `prepare_shipment_response`\n",
        "\n"
      ],
      "metadata": {
        "id": "WTEVJn0R4WJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Problems Faced\n",
        "  As I started working on this approach I got confused with 2 questions.\n",
        "  * How do I manage if user changes intent mid conversation? How will the system design look for it?\n",
        "  * How do I continue the conversation after I have switched to the another flow for like get order details etc. As I want chatbot to pick up conservation from where it left so that it looks like human like interaction.\n",
        "\n",
        "  Both these questions made it difficult to design the system. After attending the part 2 of shop assist I decided to for now make assumptions that the chatbot will not encounter above scenarios. User will not change intent and only one intent will be handled at a time.\n"
      ],
      "metadata": {
        "id": "j4aPTB9nVMue"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GmousiuEzAU",
        "outputId": "873d6e5f-e1cb-4210-b95f-2c069caf83d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "OPENAI_API_Key.txt\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI library\n",
        "!pip install -U -q openai tenacity\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/upgrad/GenAI_Course_Master/Chatbot_Project/')\n",
        "!ls\n",
        "\n",
        "# Import the libraries\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "# Set the display width to control the output width\n",
        "pd.set_option('display.width', 100)\n",
        "# Read the dataset and read the Laptop Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the libraries\n",
        "import os, json, ast\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "# read the OpenAI API key\n",
        "openai.api_key = open(\"OPENAI_API_Key.txt\", \"r\").read().strip()\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key"
      ],
      "metadata": {
        "id": "vEd32HLQHE-h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INTENTS = {\n",
        "    \"order_status\": [\"order status\", \"track my order\", \"where is my order\"],\n",
        "    \"product_info\": [\"tell me about\", \"product details\", \"product info\"],\n",
        "    \"return_policy\": [\"return policy\", \"how to return\", \"refund policy\"],\n",
        "    \"shipping_info\": [\"shipping details\", \"delivery time\", \"shipping info\"],\n",
        "}\n",
        "\n",
        "ECOM_WEBSITE = \"https://phool.co/\"\n",
        "\n",
        "REFUND_URL = \"https://phool.co/pages/terms-of-use\""
      ],
      "metadata": {
        "id": "Lq8YJLZFHhHS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(INTENTS.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLGCa8e8I0dP",
        "outputId": "100ad1ed-e0b5-45b5-a49f-b981e4801380"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['order_status', 'product_info', 'return_policy', 'shipping_info'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "    You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to handle customer support queries of customers.\n",
        "    You will be handling 5 types of user queries. Check user order, check status of shipment, get product info, answer questions about return and refund policy.\n",
        "    In case user asks questions which you do not know how to handle redirect user to manual customer support.\n",
        "\n",
        "    You need to ask relevant questions and understand the user intent first and reply back with what is user intent out of below intents.\n",
        "    If you are unable to identify intent continue the conversation till you find the intent.\n",
        "    # In below dictionary, keys are intents and the list of values for each key represent some sample input which user can give for that intent.\n",
        "    # Based on these sample inputs identify the intent of user.\n",
        "    # {delimiter}\n",
        "    # {INTENTS}\n",
        "    # {delimiter}\n",
        "\n",
        "    # Your output should be a single word intent out of {INTENTS.keys()}. If you are unable to identify indent then continue conversation with user.\n",
        "\n",
        "    \"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "yTPGFfB-HT8m"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Chat Completions API call\n",
        "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions(input, json_format = False):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
        "\n",
        "    # If the output is required to be in JSON format\n",
        "    if json_format == True:\n",
        "        # Append the input prompt to include JSON response as specified by OpenAI\n",
        "        input[0]['content'] += system_message_json_output\n",
        "\n",
        "        # JSON return type specified\n",
        "        chat_completion_json = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            response_format = { \"type\": \"json_object\"},\n",
        "            seed = 1121)\n",
        "\n",
        "        output = json.loads(chat_completion_json.choices[0].message.content)\n",
        "\n",
        "    # No JSON return type specified\n",
        "    else:\n",
        "        chat_completion = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            seed = 1211)\n",
        "\n",
        "        output = chat_completion.choices[0].message.content\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "I9zdS4DrJc_w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# system_msg = initialize_conversation()\n",
        "# debug_conversation = system_msg\n",
        "# print(system_msg[0][\"content\"])"
      ],
      "metadata": {
        "id": "u8MJV-oBJqAJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input1 = \"Hi\"\n",
        "# debug_conversation.append({'role':'user','content':user_input1})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n"
      ],
      "metadata": {
        "id": "fTdIPaIDJ0hx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# debug_conversation.append(({\"role\": \"assistant\", \"content\": debug_response_assistant}))\n"
      ],
      "metadata": {
        "id": "tEV6SA5qLP4o"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# debug_conversation"
      ],
      "metadata": {
        "id": "EWQcRA4MLWS-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input2 = \"I want to know more about refund policy\"\n",
        "# last_user_msg = user_input2\n",
        "# debug_conversation.append({'role':'user','content':user_input2})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n",
        "# print(debug_response_assistant)\n",
        "\n"
      ],
      "metadata": {
        "id": "pb-ImttRNyE-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_intent_identified(assistant_response):\n",
        "  if assistant_response in INTENTS.keys():\n",
        "    return True\n",
        "\n"
      ],
      "metadata": {
        "id": "x_Ba3qIFQPIl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_order_id(last_user_input):\n",
        "#   delimiter = \"####\"\n",
        "#   confirm_order_id_msgs = [\n",
        "#       {'role':'system','content':f\"\"\"\n",
        "#         You are a customer support executive. Need your help to check if user has passed order id in the input in the message.\n",
        "#         Reply back with a json having 2 keys.\n",
        "#         'order_id_present' which will either be 'true' or 'false' based on whether order is present,\n",
        "#         and order_id which will contain order_id when present and null when not.\n",
        "#         {delimiter}\"\"\"},\n",
        "#       {'role': 'user', 'content': f\"Here is the message {last_user_input}\"}\n",
        "#       ]\n",
        "#   response = openai.chat.completions.create(\n",
        "#       model=\"gpt-3.5-turbo\",\n",
        "#       messages = confirm_order_id_msgs,\n",
        "#       response_format={ \"type\": \"json_object\" },\n",
        "#       seed = 1234\n",
        "#       )\n",
        "#   json_output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "#   if json_output.get('order_id_present'):\n",
        "#     return json_output.get('order_id')\n"
      ],
      "metadata": {
        "id": "RHjTZPC8XQmj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moderation_check(user_input):\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    response = openai.moderations.create(input=user_input)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    moderation_output = response.results[0].flagged\n",
        "    # Check if the input was flagged by the moderation system.\n",
        "    if response.results[0].flagged == True:\n",
        "        # If flagged, return \"Flagged\"\n",
        "        return \"Flagged\"\n",
        "    else:\n",
        "        # If not flagged, return \"Not Flagged\"\n",
        "        return \"Not Flagged\""
      ],
      "metadata": {
        "id": "TUn0lydWXM0R"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order_details(order_id):\n",
        "  print(\"inside get order details\")\n",
        "  return {\n",
        "      'order_id': 122,\n",
        "      'total_amount': 299.99,\n",
        "      'delivery_status': 'Shipped',\n",
        "      'current_location': 'Warehouse B',\n",
        "      'expected_delivery_date': '2023-01-18',\n",
        "      'customer_name': 'Alice Brown',\n",
        "      'product_id': 4,\n",
        "      'product_name': 'Tablet'\n",
        "      }\n",
        "  url = \"http://your_api_endpoint/order_info\"  # Replace with your actual endpoint\n",
        "  params = {'order_id': order_id}\n",
        "  response = requests.post(url, params=params)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "      return response.json()['Result'][0]\n",
        "  else:\n",
        "      return f\"Error: Unable to fetch order details. Status code: {response.status_code}\"\n"
      ],
      "metadata": {
        "id": "dMcQ6y3Dv0iN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "available_functions = {\n",
        "    \"get_order_details\": get_order_details,\n",
        "}\n",
        "\n",
        "def execute_function_call(function_name, arguments):\n",
        "    function = available_functions.get(function_name, None)\n",
        "    if function:\n",
        "        arguments = json.loads(arguments)\n",
        "        results = function(**arguments)\n",
        "    else:\n",
        "        results = f\"Error: function {function_name} does not exist\"\n",
        "    return results\n",
        "\n",
        "\n",
        "# @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions_with_functions(input, functions):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model = MODEL,\n",
        "        messages = input,\n",
        "        functions = functions,\n",
        "        function_call = \"auto\",  # Automatically call the function when needed\n",
        "        seed = 2345)\n",
        "\n",
        "    output = chat_completion.choices[0].message.content\n",
        "\n",
        "    print(\"chat_completion.choices[0].message: \", chat_completion.choices[0].message)\n",
        "\n",
        "    #if function called then call function, get details and then call chat completion once more with function o/p\n",
        "    print(\"chat_completion.choices[0].message.function_call\", chat_completion.choices[0].message.function_call)\n",
        "    if chat_completion.choices[0].message.function_call:\n",
        "      print(\"function called\")\n",
        "\n",
        "      function_name = chat_completion.choices[0].message.function_call.name\n",
        "      arguments = chat_completion.choices[0].message.function_call.arguments\n",
        "      print(\"function_name. \", function_name)\n",
        "      print(\". rguments :\", arguments)\n",
        "      function_response = execute_function_call(function_name, json.loads(arguments))\n",
        "      print(\"function_response: \", function_response)\n",
        "\n",
        "      input.append(function_response.choices[0].message)\n",
        "      input.append({\n",
        "          \"role\": \"function\",\n",
        "          \"name\": function_name,\n",
        "          \"content\": str(function_response),\n",
        "      })\n",
        "      chat_completion = get_chat_completions_with_functions(input, functions)\n",
        "      output = chat_completion.choices[0].message.content\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "KQKizJNSl9WH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_order_info(user_input):\n",
        "  \"\"\"\n",
        "  get order id from user - get_order_id\n",
        "  once obtained - pull out order info from db/shopify API and make it json. - extract_order_info\n",
        "  Based on what user asked prepare response - prepare_order_response\n",
        "  \"\"\"\n",
        "  print(\"inside get order info\")\n",
        "  tools = [\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Gets the details of an order by order ID\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The ID of the order to retrieve\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  # first get order details\n",
        "  conversation = get_order_initialisation(user_input)\n",
        "  response_assistant = get_chat_completions_with_functions(conversation, functions=tools)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  display(response_assistant + '\\n')\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    print(\"inside while loop\")\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions_with_functions(conversation, functions=tools)  # Get assistant response\n",
        "    display(response_assistant + '\\n')  # Display assistant response\n",
        "\n"
      ],
      "metadata": {
        "id": "u8X14v85lJs2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_order_initialisation(user_input):\n",
        "\n",
        "  delimiter = \"####\"\n",
        "\n",
        "  system_message = f\"\"\"\n",
        "  You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to handle order related queries of a customer.\n",
        "  Customer has been forwarded from a chat with an existing agent as user showed intent to know about their order details.\n",
        "  You are expert in answering users order related queries.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from prev chat was {user_input}\n",
        "\n",
        "  {delimiter}\n",
        "\n",
        "  The conversation flow involves three main thoughts. Follow these chain of thoughts and converse with the customer as customer support agent.\n",
        "    - Thought 1: Obtaining the order id from user. First check if order id already exists in the users last message. If not then ask for it from user.\n",
        "    - Thought 2: Fetching details of the order from obtained order id using get_order_details.\n",
        "    - Thought 3: Find answer to user queries from output of get order details and reply back to customer with relevant order details.\n",
        "\n",
        "\n",
        "  {delimiter}\n",
        "  In case user asks questions which you do not know how to handle redirect user to manual customer support.\n",
        "\n",
        "  If you are unable to find the details of order id shared by customer then tell them \"Sorry, I am unable to find any order with order id <order id>. Please check and share order id again.\"\n",
        "\n",
        "  Order information should always be accurate based on output received from get_order_details.\n",
        "\n",
        "\n",
        "  Once you are done with helping user reply back with a single word \"exit\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = [\n",
        "      {\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "n-v73_8ZfNFL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_product_info():\n",
        "  \"\"\"\n",
        "  get ecommerce site url from settings for example phool.co\n",
        "  first check what user has asked. Form a seach query for it. create_search_query\n",
        "  Then go to website of the ecommerce company and search for the product in it. perform_search\n",
        "  then formulate the results and respond back - respond_to_user_query\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "def get_return_policy_info():\n",
        "  \"\"\"\n",
        "  get details of return and refund policy of company from urls of the pages in their websites in settings - prepare_refund_return_policy\n",
        "  answer user query based on the return and refund policy - return_return_refund_policy_info\n",
        "  \"\"\"\n",
        "  pass\n",
        "\n",
        "def get_shipment_info():\n",
        "  \"\"\"\n",
        "  get shipment awb no from user -\n",
        "  \"\"\"\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "OcU33i9RlLFL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "INTENT_to_action_map = {\n",
        "    \"order_status\": get_order_info,\n",
        "    \"product_info\": get_product_info,\n",
        "    \"return_policy\": get_return_policy_info,\n",
        "    \"shipping_info\": get_shipment_info,\n",
        "}\n",
        "\n",
        "\n",
        "def chatbot():\n",
        "  conversation = initialize_conversation()\n",
        "  is_intent_identified = False\n",
        "  introduction = get_chat_completions(conversation)\n",
        "  display(introduction + '\\n')\n",
        "  user_input = ''\n",
        "  while(user_input != \"exit\"):\n",
        "    user_input = input(\"\")\n",
        "    moderation = moderation_check(user_input)\n",
        "    if moderation == 'Flagged':\n",
        "      display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break\n",
        "    print(\"is intent identified. : \", is_intent_identified)\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "    response_assistant = get_chat_completions(conversation)\n",
        "    is_intent_identified = check_intent_identified(response_assistant)\n",
        "    if is_intent_identified:\n",
        "      print(\"intent identified\")\n",
        "      action = INTENT_to_action_map.get(response_assistant)\n",
        "      action(user_input)\n",
        "    else:\n",
        "      conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "      display(\"\\n\" + str(response_assistant) + \"\\n\")\n"
      ],
      "metadata": {
        "id": "tbVSaFVIyalV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hmxawazSfnd9",
        "outputId": "d4296b68-3096-4fc0-b8b3-0ba9d5acfe6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'order_status\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-aac704dbd9c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-6c6c83eb7cf7>\u001b[0m in \u001b[0;36mchatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmoderation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoderation_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmoderation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Flagged'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # {delimiter}\n",
        "    # once you find intent take action as follows:\n",
        "    # for check order details intent follow below steps:\n",
        "    #   1. first get order id from user\n",
        "    #   2. Once received get the order details\n",
        "    #   3. Prepare the answer to user query from the order details received.\n",
        "    # {delimiter}\n",
        "\n",
        "    # for product info intent:\n",
        "    #   1. get details of what info user is looking for\n",
        "    #   2. prepare search terms from user input\n",
        "    #   3. Search website {ECOM_WEBSITE} for the search term\n",
        "    #   4. if results found prepare response and respond back to user\n",
        "    #   5. if relevant results not found redirect user to manual support\n",
        "\n",
        "    # for refund or return policy questions:\n",
        "    #   1. Go to website {REFUND_URL} and get details of refund and return policy\n",
        "    #   2. check if answer to user query is present in refund and return policy\n",
        "    #   3. If present reply back to user with relevant details\n",
        "    #   4. if relevant results not found redirect user to manual support\n"
      ],
      "metadata": {
        "id": "fEEUaojBfbke"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}