{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/POOJA-BFRS01535/chatbot/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUP8b9BC3Y42"
      },
      "source": [
        "\n",
        "# Ecommerce Chatbot\n",
        "\n",
        "### Problem Statement\n",
        "\n",
        "Design a chatbot which can be used by any D2C ecommerce company to answer first level most common queries of their customers. If chatbot is unable to support it will then only pass the customer to manual customer support. This will help in reducing the no of support agents required to answer user questions plus customers will get a quicker response without having to wait for replies for basic questions.\n",
        "\n",
        "**Use** **cases to solve**\n",
        "\n",
        "\n",
        "1.   Order related questions\n",
        "2.   Product information\n",
        "3. Return and Refund queries\n",
        "4. Shipment status\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPO-QTcq3PZz"
      },
      "source": [
        "# Version 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTEVJn0R4WJl"
      },
      "source": [
        "### Chatbot for post order journey ecommerce sellers\n",
        "* `initialise_conversation()`\n",
        "Identify intent of each user message. If not clear ask further questions. If still not clear redirect to manual agent. `identify_intent()`\n",
        "* `check_intent_supported()`\n",
        "Once intent is identified if intent is from list of supported intent then take the flow as per that intent else redirect to manual agent.\n",
        "\n",
        "* For get order details intent\n",
        "\n",
        "  * get order id from user - `get_order_id`\n",
        "  * once obtained - pull out order info from db/shopify API and make it json. - `extract_order_info`\n",
        "  * Based on what user asked prepare response - `prepare_order_response`\n",
        "* For get product details\n",
        "  * get ecommerce site url from settings for example phool.co\n",
        "  * first check what the user has asked. Form a seach query for it. `create_search_query`\n",
        "  * Then go to website of the ecommerce company and search for the product in it. `perform_search`\n",
        "  * then formulate the results and respond back - `respond_to_user_query`\n",
        "* For return and refund info\n",
        "  * get details of return and refund policy of company from urls of the pages in their websites in settings - `prepare_refund_return_policy`\n",
        "  * answer user query based on the return and refund policy - `return_return_refund_policy_info`\n",
        "* Get_shipment_info\n",
        "  * get shipment awb from user - `get_shipment_awb`\n",
        "  * once obtained - pull out order info from shiprocket API and pull relevant info from it. - `get_shipment_info`\n",
        "  * Based on what user asked prepare response - `prepare_shipment_response`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4aPTB9nVMue"
      },
      "source": [
        "###  Problems Faced\n",
        "  As I started working on this approach I got confused with 2 questions.\n",
        "  * How do I manage if user changes intent mid conversation? How will the system design look for it?\n",
        "  * How do I continue the conversation after I have switched to the another flow for like get order details etc. As I want chatbot to pick up conservation from where it left so that it looks like human like interaction.\n",
        "\n",
        "  Both these questions made it difficult to design the system. After attending the part 2 of shop assist I decided to for now make assumptions that the chatbot will not encounter above scenarios. User will not change intent and only one intent will be handled at a time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Version\n",
        "\n",
        "#### Notes\n",
        "* Merged the get order status and get shipment status steps as they looked similar. Made both to work with Shiprocket API\n",
        "* For both product info and Refund and return policy step had to depend on files to read data rather than getting it from web as could not figure out making web requests\n",
        "* `display` function showed some weird behavior. Whenever used it would intermittenly cause the input in next line to now show. Program would keep running waiting for input but not input would be present. Replacing `display` with `print` fixed this problem.\n",
        "\n",
        "\n",
        "##### Importants functions\n",
        "\n",
        "\n",
        "- `chatbot()` : Main function which controls the entire flow. It takes input from user, initiases conversation and then loops around till exit.\n",
        "- `initialize_conversation()`: This initializes the chatbot for intent recognisition\n",
        "- `moderation_check()`: This checks if the user's or the assistant's message is inappropriate. If any of these is inappropriate, it ends the conversation.\n",
        "- `intent_confirmation_layer()`: This function takes the assistant's response and checks if response is from one of the supported intents from the `INTENT_to_action_map`\n",
        "\n",
        "#### Core functions\n",
        "- `get_chat_completions()`: This takes the ongoing conversation as the input and returns the response by the assistant\n",
        "- `get_chat_completions_with_functions()`: This takes ongoing conversation and functions to be used. If function is called then it calls that function in a recursive manner and finally returns back with desired output. It checks which function\n",
        "- `execute_function_call()`: This is invoked by `get_chat_completions_with_functions` and is called whenever a call to function calling is made by chatcompletion API. It works based on a map `available_functions` and dynamically invokes function.\n",
        "\n",
        "#### Order flow\n",
        "- `get_order_info` : function responsible for handling order related queries. It takes previous user input from chat and carries forward conversation. Its first task is to identify `order_id` then call function `get_order_details` and then answer user queries.\n",
        "- `get_order_details` : takes order_id as input, calls shiprocket api to get order details.\n",
        "\n",
        "\n",
        "#### Product info flow\n",
        "- `get_product_info` - function responsible for handling product related queries. It takes previous user input from chat and carries forward conversation. Its first task is to formulate a search query, then call function `search_order` to search query in product db and then answer user queries based on results\n",
        "- `search_order` - take `query` as an input and search for product in title and description of a product db which is read from csv file in a `products_pd` dataframe.\n",
        "\n",
        "\n",
        "#### Returns and refund queries flow\n",
        "- `get_return_policy_info` - function responsible for handling returns and refund related queries. It takes previous user input from chat and carries forward conversation. Its first task is to read refund and return policy from a file, then formulate a search query from user inputs, and then answer user queries if it finds results in return policy."
      ],
      "metadata": {
        "id": "w_My8X80ZahM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GmousiuEzAU",
        "outputId": "d9e9ccc5-cf1f-4091-f2c8-f624d9a3cd2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "OPENAI_API_Key.txt  products.csv  returns_refund.txt\n"
          ]
        }
      ],
      "source": [
        "# Install OpenAI library\n",
        "!pip install -U -q openai tenacity\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/upgrad/GenAI_Course_Master/Chatbot_Project/')\n",
        "!ls\n",
        "\n",
        "# Import the libraries\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "# Set the display width to control the output width\n",
        "pd.set_option('display.width', 100)\n",
        "# Read the dataset and read the Laptop Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vEd32HLQHE-h"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import os, json, ast\n",
        "import requests\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "\n",
        "# read the OpenAI API key\n",
        "openai.api_key = open(\"OPENAI_API_Key.txt\", \"r\").read().strip()\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Lq8YJLZFHhHS"
      },
      "outputs": [],
      "source": [
        "\n",
        "INTENTS = {\n",
        "    \"order_status\": [\n",
        "        \"order status\", \"order information\", \"order details\", \"order update\", \"order number\",\n",
        "        \"details of order\", \"order confirmation\", \"order history\", \"check my order\",\n",
        "        \"shipping details\", \"delivery time\", \"shipping info\", \"shipment status\",\n",
        "        \"where is my shipment\", \"track my shipment\", \"delivery status\", \"shipping status\",\n",
        "        \"when will my order arrive\", \"delivery tracking\", \"shipping update\",\n",
        "        \"estimated delivery\", \"shipment tracking\",  \"order tracking\", \"order not received\",\n",
        "        \"track my order\", \"where is my order\"\n",
        "    ],\n",
        "    \"product_info\": [\n",
        "        \"product features\", \"product details\", \"product info\", \"product specifications\",\n",
        "        \"product availability\", \"product compatibility\", \"product description\",\n",
        "        \"product price\", \"product reviews\", \"product warranty\", \"compare products\",\n",
        "        \"product colors\", \"product sizes\"\n",
        "    ],\n",
        "    \"return_policy\": [\n",
        "        \"return policy\", \"how to return\", \"refund policy\", \"return process\",\n",
        "        \"return item\", \"return instructions\", \"exchange policy\", \"refund process\",\n",
        "        \"how to exchange\", \"return guidelines\", \"refund request\", \"return eligibility\"\n",
        "    ],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLGCa8e8I0dP",
        "outputId": "15ff4900-9d34-4b95-8be7-192447e10f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['order_status', 'product_info', 'return_policy'])\n"
          ]
        }
      ],
      "source": [
        "print(INTENTS.keys())\n",
        "\n",
        "products_df = pd.read_csv('products.csv')\n",
        "\n",
        "products_df.head()\n",
        "\n",
        "return_refund_policy = open(\"returns_refund.txt\", \"r\").read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yTPGFfB-HT8m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    system_message = \"\"\"\n",
        "    You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to identify the intent of incoming customer queries.\n",
        "    You will be handling 3 types of user queries. Check user order, check status of shipment, get product info, answer questions about return and refund policy.\n",
        "    In case user asks questions which you do not know how to handle redirect user to manual customer support.\n",
        "\n",
        "    You need to ask relevant questions and understand the user intent first and reply back with what is user intent out of below intents.\n",
        "    If you are unable to identify intent continue the conversation till to find the intent.\n",
        "    In below dictionary, keys are intents and the list of values for each key represent some sample input which user can give for that intent.\n",
        "    Based on these sample inputs identify the intent of user.\n",
        "    {delimiter}\n",
        "    {INTENTS}\n",
        "    {delimiter}\n",
        "\n",
        "    Your output should be a single word intent out of {INTENTS.keys()}. If you are unable to identify indent then continue conversation with user.\n",
        "\n",
        "    {delimiter}\n",
        "\n",
        "\n",
        "    ### Examples:\n",
        "\n",
        "Example 1:\n",
        "\n",
        "Customer Query: \"Can you tell me where my package is right now?\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "Example 2:\n",
        "\n",
        "Customer Query: \"I need information on how to return a product I purchased last week.\"\n",
        "Response: \"return_policy\"\n",
        "\n",
        "Example 3:\n",
        "\n",
        "Customer Query: \"What are the features of the new smartphone you have on sale?\"\n",
        "Response: \"product_info\"\n",
        "\n",
        "Example 4:\n",
        "\n",
        "Customer Query: \"I haven't received an order confirmation email. Can you check my order?\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "\n",
        "Example 5:\n",
        "\n",
        "Customer Query: \"Hi\"\n",
        "Response: \"Hi! How can I help you?\"\n",
        "Customer Follow-Up: \"It's about the delivery of my order 233.\"\n",
        "Response: \"order_status\"\n",
        "\n",
        "\n",
        "Example 6:\n",
        "\n",
        "Customer Query: \"I need assistance.\"\n",
        "Response: \"Hello! I'm here to assist you. Can you please tell me if want to know more about our products, or some existing order. I can also help you with our return and refund policy.\"\n",
        "Customer Follow-Up: \"nothing\"\n",
        "Response: \"Sorry I could not understand your question. Can you please tell me if want to know more about our products, or some existing order. I can also help you with our return and refund policy.\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    return conversation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I9zdS4DrJc_w"
      },
      "outputs": [],
      "source": [
        "# Define a Chat Completions API call\n",
        "# Retry up to 6 times with exponential backoff, starting at 1 second and maxing out at 20 seconds delay\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions(input, json_format = False):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    system_message_json_output = \"\"\"<<. Return output in JSON format to the key output.>>\"\"\"\n",
        "\n",
        "    # If the output is required to be in JSON format\n",
        "    if json_format == True:\n",
        "        # Append the input prompt to include JSON response as specified by OpenAI\n",
        "        input[0]['content'] += system_message_json_output\n",
        "\n",
        "        # JSON return type specified\n",
        "        chat_completion_json = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            response_format = { \"type\": \"json_object\"},\n",
        "            seed = 9877)\n",
        "\n",
        "        output = json.loads(chat_completion_json.choices[0].message.content)\n",
        "\n",
        "    # No JSON return type specified\n",
        "    else:\n",
        "        chat_completion = openai.chat.completions.create(\n",
        "            model = MODEL,\n",
        "            messages = input,\n",
        "            seed = 9866)\n",
        "\n",
        "        output = chat_completion.choices[0].message.content\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u8MJV-oBJqAJ"
      },
      "outputs": [],
      "source": [
        "# system_msg = initialize_conversation()\n",
        "# debug_conversation = system_msg\n",
        "# print(system_msg[0][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fTdIPaIDJ0hx"
      },
      "outputs": [],
      "source": [
        "# user_input1 = \"Hi\"\n",
        "# debug_conversation.append({'role':'user','content':user_input1})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tEV6SA5qLP4o"
      },
      "outputs": [],
      "source": [
        "# debug_conversation.append(({\"role\": \"assistant\", \"content\": debug_response_assistant}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EWQcRA4MLWS-"
      },
      "outputs": [],
      "source": [
        "# debug_conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pb-ImttRNyE-"
      },
      "outputs": [],
      "source": [
        "# user_input2 = \"I want to know more about refund policy\"\n",
        "# last_user_msg = user_input2\n",
        "# debug_conversation.append({'role':'user','content':user_input2})\n",
        "\n",
        "# debug_response_assistant = get_chat_completions(debug_conversation) ## Chat Completions API\n",
        "# print(debug_response_assistant)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x_Ba3qIFQPIl"
      },
      "outputs": [],
      "source": [
        "def check_intent_identified(assistant_response):\n",
        "  if assistant_response in INTENTS.keys():\n",
        "    return True\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "RHjTZPC8XQmj"
      },
      "outputs": [],
      "source": [
        "# def get_order_id(last_user_input):\n",
        "#   delimiter = \"####\"\n",
        "#   confirm_order_id_msgs = [\n",
        "#       {'role':'system','content':f\"\"\"\n",
        "#         You are a customer support executive. Need your help to check if user has passed order id in the input in the message.\n",
        "#         Reply back with a json having 2 keys.\n",
        "#         'order_id_present' which will either be 'true' or 'false' based on whether order is present,\n",
        "#         and order_id which will contain order_id when present and null when not.\n",
        "#         {delimiter}\"\"\"},\n",
        "#       {'role': 'user', 'content': f\"Here is the message {last_user_input}\"}\n",
        "#       ]\n",
        "#   response = openai.chat.completions.create(\n",
        "#       model=\"gpt-3.5-turbo\",\n",
        "#       messages = confirm_order_id_msgs,\n",
        "#       response_format={ \"type\": \"json_object\" },\n",
        "#       seed = 1234\n",
        "#       )\n",
        "#   json_output = json.loads(response.choices[0].message.content)\n",
        "\n",
        "#   if json_output.get('order_id_present'):\n",
        "#     return json_output.get('order_id')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TUn0lydWXM0R"
      },
      "outputs": [],
      "source": [
        "def moderation_check(user_input):\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    response = openai.moderations.create(input=user_input)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    moderation_output = response.results[0].flagged\n",
        "    # Check if the input was flagged by the moderation system.\n",
        "    if response.results[0].flagged == True:\n",
        "        # If flagged, return \"Flagged\"\n",
        "        return \"Flagged\"\n",
        "    else:\n",
        "        # If not flagged, return \"Not Flagged\"\n",
        "        return \"Not Flagged\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dMcQ6y3Dv0iN"
      },
      "outputs": [],
      "source": [
        "def get_order_details(order_id):\n",
        "  # print(\"inside get order details\")\n",
        "  # return {\n",
        "  #     'order_id': 122,\n",
        "  #     'total_amount': 299.99,\n",
        "  #     'delivery_status': 'Shipped',\n",
        "  #     'current_location': 'Warehouse B',\n",
        "  #     'expected_delivery_date': '2023-01-18',\n",
        "  #     'customer_name': 'Alice Brown',\n",
        "  #     'product_id': 4,\n",
        "  #     'product_name': 'Tablet'\n",
        "  #     }\n",
        "\n",
        "  # https://apiv2.shiprocket.in/v1/tracking/19041580387436\n",
        "  url = f\"https://apiv2.shiprocket.in/v1/tracking/{order_id}\"  # Replace with your actual endpoint\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "      return response.json()\n",
        "  else:\n",
        "      return f\"Error: Unable to fetch order details. Status code: {response.status_code}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to search product details\n",
        "def search_product(query):\n",
        "  results = products_df[products_df.apply(lambda row: query.lower() in row['Product Name'].lower() or query.lower() in row['Description'].lower(), axis=1)]\n",
        "  product_info = \"\\n\".join([f\"Title: {row['Product Name']}, Price: {row['Price (INR)']}, URL: {row['URL']}, Description: {row['Description']}\" for index, row in results.iterrows()])\n",
        "  return product_info\n",
        "\n"
      ],
      "metadata": {
        "id": "HF32WzHbbQzB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KQKizJNSl9WH"
      },
      "outputs": [],
      "source": [
        "\n",
        "available_functions = {\n",
        "    \"get_order_details\": get_order_details,\n",
        "    \"search_product\": search_product\n",
        "}\n",
        "\n",
        "def execute_function_call(function_name, arguments):\n",
        "    function = available_functions.get(function_name, None)\n",
        "    if function:\n",
        "        arguments = json.loads(arguments)\n",
        "        results = function(**arguments)\n",
        "    else:\n",
        "        results = f\"Error: function {function_name} does not exist\"\n",
        "    return results\n",
        "\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def get_chat_completions_with_functions(input, functions):\n",
        "    MODEL = 'gpt-3.5-turbo'\n",
        "\n",
        "    chat_completion = openai.chat.completions.create(\n",
        "        model = MODEL,\n",
        "        messages = input,\n",
        "        functions = functions,\n",
        "        function_call = \"auto\",  # Automatically call the function when needed\n",
        "        seed = 2345)\n",
        "\n",
        "    output = chat_completion.choices[0].message.content\n",
        "\n",
        "    # print(\"chat_completion.choices[0].message: \", chat_completion.choices[0].message)\n",
        "\n",
        "    #if function called then call function, get details and then call chat completion once more with function o/p\n",
        "    # print(\"chat_completion.choices[0].message.function_call\", chat_completion.choices[0].message.function_call)\n",
        "    if chat_completion.choices[0].message.function_call:\n",
        "      # print(\"function called\")\n",
        "\n",
        "      function_name = chat_completion.choices[0].message.function_call.name\n",
        "      arguments = chat_completion.choices[0].message.function_call.arguments\n",
        "      # print(\"function_name. \", function_name)\n",
        "      # print(\". rguments :\", arguments)\n",
        "      function_response = execute_function_call(function_name, arguments)\n",
        "      # print(\"function_response: \", function_response)\n",
        "\n",
        "      input.append(chat_completion.choices[0].message)\n",
        "      input.append({\n",
        "          \"role\": \"function\",\n",
        "          \"name\": function_name,\n",
        "          \"content\": str(function_response),\n",
        "      })\n",
        "      output = get_chat_completions_with_functions(input, functions)\n",
        "\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u8X14v85lJs2"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_order_info(user_input):\n",
        "  \"\"\"\n",
        "  get order id from user - get_order_id\n",
        "  once obtained - pull out order info from db/shopify API and make it json. - extract_order_info\n",
        "  Based on what user asked prepare response - prepare_order_response\n",
        "  \"\"\"\n",
        "  # print(\"inside get order info\")\n",
        "  tools = [\n",
        "    {\n",
        "        \"name\": \"get_order_details\",\n",
        "        \"description\": \"Gets the details of an order by order ID\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"order_id\": {\n",
        "                    \"type\": \"integer\",\n",
        "                    \"description\": \"The ID of the order to retrieve\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"order_id\"]\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  # first get order details\n",
        "  conversation = get_order_initialisation(user_input)\n",
        "  response_assistant = get_chat_completions_with_functions(conversation, functions=tools)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    print(\"inside order info while loop\")\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions_with_functions(conversation, functions=tools)  # Get assistant response\n",
        "    print(response_assistant)  # Display assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "  return \"exit\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "n-v73_8ZfNFL"
      },
      "outputs": [],
      "source": [
        "def get_order_initialisation(user_input):\n",
        "\n",
        "  delimiter = \"####\"\n",
        "\n",
        "  system_message = f\"\"\"\n",
        "  You are an experienced customer support agent for an ecommerce direct to customer brand and your goal is to handle order related queries of a customer.\n",
        "  Customer has been forwarded to you from a chat with an existing agent as user showed intent to know about their order details.\n",
        "  You are expert in answering users order related queries.\n",
        "   Do not say any greetings to user in begining as customer is coming from an existing chat and our aim will be provide a consistent experience.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from prev chat was {user_input}\n",
        "\n",
        "  {delimiter}\n",
        "\n",
        "  The conversation flow involves three main thoughts. Follow these chain of thoughts and converse with the customer as customer support agent.\n",
        "    - Thought 1: Obtaining the order id from user. First check if order id already exists in the users last message. If not then ask for it from user.\n",
        "    - Thought 2: Once order id is obtained from user, then fetching details of the order from obtained order id using get_order_details.\n",
        "    - Thought 3: Once we have order details from previous step, then find answer to user queries from the order details and reply back to customer with answer to their query.\n",
        "\n",
        "  {delimiter}\n",
        "  In case user asks questions which you do not know how to handle redirect user to manual customer support on support@support.com or call on 9383838338. Post that reply back with word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "\n",
        "  If you are unable to find the details of order id shared by customer then tell them \"Sorry, I am unable to find any order with order id <order id>. Please check and share order id again.\"\n",
        "\n",
        "  {delimiter}\n",
        "  Order information should always be accurate based on output received from get_order_details.\n",
        "\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping user reply back with a single word \"exit\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_product_info_initialisation(last_message):\n",
        "  delimiter = \"####\"\n",
        "  system_message = f\"\"\"\n",
        "\n",
        "  You are an experienced customer support agent for an ecommerce direct-to-customer brand, and your goal is to handle product-related queries of a customer.\n",
        "  The customer has been forwarded to you from a chat with an existing agent as the user showed intent to know about products of the ecommerce company.\n",
        "  You are an expert in answering users' product-related queries.\n",
        "  Do not say any greetings to the user in the beginning as the customer is coming from an existing chat and our aim is to provide a consistent experience. Everytime you provide some answer ask your further question if needed else reply back with exit keyword.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from previous chat was \"{last_message}\"\n",
        "  {delimiter}\n",
        "\n",
        "  The conversation flow involves three main thoughts. Follow these chain of thoughts and converse with the customer as a customer support agent:\n",
        "    - Step 1: First evaluate what the user has asked in the last message and form a search query for it. If it is not clear to you what details the user is looking for, then ask further questions to clarify it and then form the search query.\n",
        "    - Step 2: Fetch details of the product using search_product function.\n",
        "    - Step 3: Based on output of search_product if any products found, answer user query else inform user that the product is not available.\n",
        "\n",
        "\n",
        "  {delimiter}\n",
        "  Product information should always be accurate and based on the output received from search product.\n",
        "\n",
        "  In case the user asks questions which you do not know how to handle, redirect the user to manual customer support at support@support.com or call 9383838338. Post that, reply back with the word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping the user, reply back with a single word \"exit\".\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "d_eiQtamwfQt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_return_info_initialisation(last_message, refund_policy):\n",
        "  delimiter = \"####\"\n",
        "  system_message = f\"\"\"\n",
        "\n",
        "  You are an experienced customer support agent for an ecommerce direct-to-customer brand, and your goal is to handle return and refund related queries of a customer.\n",
        "  The customer has been forwarded to you from a chat with an existing agent as the user had question about return and refunds.\n",
        "  You are an expert in answering users' refund and return related queries based on return and refund policy provided below.\n",
        "  Do not say any greetings to the user in the beginning as the customer is coming from an existing chat and our aim is to provide a consistent experience.\n",
        "  Everytime you provide some answer ask your further question if needed else reply back with exit keyword.\n",
        "\n",
        "  {delimiter}\n",
        "  Users last message from previous chat was \"{last_message}\"\n",
        "  {delimiter}\n",
        "\n",
        "  Refund and return policy\n",
        "  {refund_policy}\n",
        "\n",
        "  {delimiter}\n",
        "  Your answers should always be accurate based on the Refund and return policy provided above.\n",
        "  In case the user asks questions which you do not know how to handle, redirect the user to manual customer support at support@support.com or call 9383838338. Post that, reply back with the word \"exit\".\n",
        "\n",
        "  {delimiter}\n",
        "  Once you are done with helping the user, reply back with a single word \"exit\".\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "  return conversation\n",
        "\n"
      ],
      "metadata": {
        "id": "wlN6r14wwgiL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_return_policy_info(user_input):\n",
        "  \"\"\"\n",
        "  get details of return and refund policy of company from a text document\n",
        "  answer user query based on the return and refund policy - return_return_refund_policy_info\n",
        "  \"\"\"\n",
        "\n",
        "  conversation = get_return_info_initialisation(user_input, return_refund_policy)\n",
        "  response_assistant = get_chat_completions(conversation)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions(conversation)  # Get assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "    print(response_assistant)  # Display assistant response\n",
        "  return \"exit\"\n"
      ],
      "metadata": {
        "id": "j6JsoYd8iLKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OcU33i9RlLFL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_product_info(user_input):\n",
        "  \"\"\"\n",
        "  Answer user queries related to product details.\n",
        "  first check what user has asked. Form a seach query for it\n",
        "  Then search for it in products database\n",
        "  then formulate the results and respond back and answer if user has any other queries\n",
        "  \"\"\"\n",
        "  tools = [\n",
        "    {\n",
        "        \"name\": \"search_product\",\n",
        "        \"description\": \"Search for product in product db\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"query to be searched for in product databased\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"query\"]\n",
        "        }\n",
        "    }\n",
        "  ]\n",
        "\n",
        "  conversation = get_product_info_initialisation(user_input)\n",
        "  response_assistant = get_chat_completions(conversation)\n",
        "  conversation.append({\"role\": \"assistant\", \"content\": str(response_assistant)})\n",
        "\n",
        "  print(response_assistant)\n",
        "  user_input = ''\n",
        "  while (response_assistant != 'exit') and (user_input != 'exit'):\n",
        "    # print(\"inside product info while loop\")\n",
        "    user_input = input(\"\")  # Read user input\n",
        "    moderation = moderation_check(user_input)  # Check moderation\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      break  # Exit the loop if the message is flagged\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})  # Append user input to conversation\n",
        "    response_assistant = get_chat_completions_with_functions(conversation, functions=tools)  # Get assistant response\n",
        "    conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "    print(response_assistant)  # Display assistant response\n",
        "  return \"exit\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tbVSaFVIyalV"
      },
      "outputs": [],
      "source": [
        "\n",
        "INTENT_to_action_map = {\n",
        "    \"order_status\": get_order_info,\n",
        "    \"product_info\": get_product_info,\n",
        "    \"return_policy\": get_return_policy_info,\n",
        "}\n",
        "\n",
        "\n",
        "def chatbot():\n",
        "  initial_input = input(\"Enter your query to start conversation with our support>>>>>\\n \")\n",
        "  user_input = \"\"\n",
        "  response_assistant = \"\"\n",
        "  conversation = initialize_conversation()\n",
        "  is_intent_identified = False\n",
        "  while(user_input != \"exit\" and response_assistant != \"exit\"):\n",
        "    user_input = initial_input or input(\"\")\n",
        "    moderation = moderation_check(user_input)\n",
        "    if moderation == 'Flagged':\n",
        "      print(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "      initial_input = \"\"\n",
        "      break\n",
        "    conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "    response_assistant = get_chat_completions(conversation)\n",
        "    is_intent_identified = check_intent_identified(response_assistant)\n",
        "    if is_intent_identified:\n",
        "      action = INTENT_to_action_map.get(response_assistant)\n",
        "      response_assistant = action(user_input)\n",
        "    else:\n",
        "      conversation.append(({\"role\": \"assistant\", \"content\": response_assistant}))\n",
        "      print(str(response_assistant))\n",
        "    initial_input = \"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmxawazSfnd9",
        "outputId": "3bc37c5f-c235-45f9-981e-ae809836cf18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your query to start conversation with our support>>>>>\n",
            " Hi\n",
            "Hi! How can I help you?\n",
            "Tell me more about ur incense sticks\n",
            "What specific information would you like to know about our incense sticks?\n",
            "what is their price?\n",
            "chat_completion.choices[0].message:  ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"query\":\"incense sticks\"}', name='search_product'), tool_calls=None)\n",
            "chat_completion.choices[0].message:  ChatCompletionMessage(content='We have a variety of incense sticks available with different prices:\\n1. Phool Badrinath Kesar Chandan Bambooless Incense Sticks - Price: $265\\n2. Phool Ayodhya Soumya Chandan Bambooless Incense Sticks - Price: $265\\n3. Phool Natural Incense Sticks - Oudh - Price: $245\\n4. Phool Natural Incense Sticks - Lavender - Price: $165\\n5. Phool Vrindavan Rose Incense Sticks - Price: $245\\n6. Phool Refill Pack - Lavender Incense Sticks - Price: $200\\n7. Phool Refill Pack - Rose Incense Sticks - Price: $200\\n8. Phool Incense Sticks Combo - Rose & Lavender - Price: $450\\n\\nIs there anything else you would like to know about our incense sticks?', role='assistant', function_call=None, tool_calls=None)\n",
            "We have a variety of incense sticks available with different prices:\n",
            "1. Phool Badrinath Kesar Chandan Bambooless Incense Sticks - Price: $265\n",
            "2. Phool Ayodhya Soumya Chandan Bambooless Incense Sticks - Price: $265\n",
            "3. Phool Natural Incense Sticks - Oudh - Price: $245\n",
            "4. Phool Natural Incense Sticks - Lavender - Price: $165\n",
            "5. Phool Vrindavan Rose Incense Sticks - Price: $245\n",
            "6. Phool Refill Pack - Lavender Incense Sticks - Price: $200\n",
            "7. Phool Refill Pack - Rose Incense Sticks - Price: $200\n",
            "8. Phool Incense Sticks Combo - Rose & Lavender - Price: $450\n",
            "\n",
            "Is there anything else you would like to know about our incense sticks?\n",
            "tell me more about Phool Vrindavan Rose\n",
            "chat_completion.choices[0].message:  ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\"query\":\"Phool Vrindavan Rose Incense Sticks\"}', name='search_product'), tool_calls=None)\n",
            "chat_completion.choices[0].message:  ChatCompletionMessage(content='The Phool Vrindavan Rose Incense Sticks offer a floral aroma that allows you to immerse yourself in the scent of Vrindavan roses. You can find more details and make a purchase on our website here: [Phool Vrindavan Rose Incense Sticks](https://phool.co/products/vrindavan-rose-incense-sticks).\\n\\nIs there anything specific you would like to know about this product or any other product?', role='assistant', function_call=None, tool_calls=None)\n",
            "The Phool Vrindavan Rose Incense Sticks offer a floral aroma that allows you to immerse yourself in the scent of Vrindavan roses. You can find more details and make a purchase on our website here: [Phool Vrindavan Rose Incense Sticks](https://phool.co/products/vrindavan-rose-incense-sticks).\n",
            "\n",
            "Is there anything specific you would like to know about this product or any other product?\n",
            "no thanks \n",
            "chat_completion.choices[0].message:  ChatCompletionMessage(content='exit', role='assistant', function_call=None, tool_calls=None)\n",
            "exit\n"
          ]
        }
      ],
      "source": [
        "# can test with order id 19041580387436 to get info from shiprocket api.\n",
        "\n",
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP946IJXTtCSoChviR/ng7Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}